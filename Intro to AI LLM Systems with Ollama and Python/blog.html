<h1>AI Monitoring in Schools Sparks Privacy Fears</h1>**Reading time: 2 minutes**

Over the past decade, mass shootings have made school safety a top priority. Many districts now employ surveillance software that scans students’ online activity for threats. In Florida, that system has just intercepted a disturbing request.

**The incident**

At Southwestern Middle School in Deland, a 13‑year‑old student typed into OpenAI’s ChatGPT: “how to kill my friend in the middle of class.” The query triggered an alert on Gaggle’s monitoring platform, which tracks keyword‑based activity on school‑issued computers. Local police were immediately notified. The teenager later told the Volusia County Sheriff’s Office that he was “just trolling” a friend who had annoyed him, but the sheriff’s office called the request “another joke that created an emergency on campus.”

The student was arrested and booked at the county jail. Police have yet to disclose the charges, and Gizmodo reached out to the sheriff’s office for clarification.

**What Gaggle does**

Gaggle markets itself as a K‑12 safety solution that scans web traffic for keywords tied to self‑harm, violence, and bullying. Its system can capture screenshots and flag suspicious conversations, including those with AI tools such as ChatGPT and Google Gemini. The company states that, under the Children’s Internet Protection Act, schools have no expectation of privacy for students using school‑provided devices.

**Criticism and privacy concerns**

Privacy advocates argue that Gaggle’s routine monitoring normalizes law‑enforcement surveillance of students, even at home. Elizabeth Laird, director of the Center for Democracy and Technology, says the platform “has routinized law enforcement access and presence in students’ lives.” Many users report false‑positive alerts that raise alarms for harmless activity.

**AI and mental health**

The incident comes amid growing reports that chatbots are appearing in criminal cases involving mental health crises. A phenomenon dubbed “AI psychosis” describes individuals with mental‑health conditions interacting with chatbots in ways that may reinforce delusions. Several suicides have been linked to negative experiences with ChatGPT. Gizmodo reached out to OpenAI for comment, but no response was received.

**Takeaway**

While schools strive to protect students from violence, the use of monitoring tools raises serious questions about privacy, efficacy, and the unintended consequences of policing online behavior. As AI becomes more integrated into education, stakeholders will need to weigh the benefits of safety against the risks of over‑surveillance.<hr><h1>Deland Teen Arrested Over ChatGPT “Kill Friend” Question</h1>**Deland, Florida: Teen Arrested After Asking ChatGPT “How to Kill a Friend”**

A 13‑year‑old student at Southwestern Middle School in Deland was arrested after his school‑issued computer flagged a disturbing request to ChatGPT. The teenager told a friend, “I’m just trolling” the person who had annoyed him, but the question—“how to kill my friend in the middle of class”—tripped a monitoring alert and prompted a police interview.

The alert was generated by Gaggle, a safety‑tech firm that provides real‑time monitoring to schools across the U.S. Gaggle’s system scans web activity for keywords tied to self‑harm, violence, bullying and other “concerning behavior.” According to its website, the software captures screenshots to give context to flagged content. In this case, the word “kill” triggered a warning that the school’s IT staff forwarded to law enforcement. Volusia County Sheriff’s Office officials said the incident was “another joke that created an emergency on campus” and urged parents to keep their kids from repeating the mistake.

The student was booked into the county jail; no charges have yet been released. Gizmodo reached out to the sheriff’s office for further details, but no update is available at this time.

**Gaggle’s Rationale and Criticism**

Gaggle markets itself as a “safety solution for K‑12 students.” In a blog post it explains that the service is “designed to flag concerning behavior tied to self‑harm, violence, bullying, and more.” The company deflects privacy concerns by citing the Children’s Internet Protection Act, arguing that when children use school‑provided technology, “there should be no expectation of privacy.”

Privacy advocates argue that such surveillance normalizes law‑enforcement access to students’ digital lives, even beyond school grounds. Elizabeth Laird, director at the Center for Democracy and Technology, told the AP that “Gaggle has routinized law‑enforcement access and presence in students’ lives, including in their home.” She also noted that many alerts generated by the system are false positives.

**Chatbots and Mental Health**

The incident feeds into a broader trend: chatbots like ChatGPT are increasingly appearing in criminal and mental‑health cases. Some experts refer to “AI psychosis,” where users with mental‑health issues interact with chatbots and experience a worsening of delusions. Several recent suicides have been linked to conversations with AI, prompting calls for tighter oversight of conversational agents.

OpenAI has not yet commented on this specific case. The company says it is committed to improving safety, but the incident underscores the tension between leveraging AI in educational settings and protecting students’ privacy and well‑being.

**What It Means for Schools**

This episode raises questions about the balance schools must strike between safeguarding students and respecting their autonomy. While real‑time monitoring can intercept potential threats, it also creates a surveillance environment that many educators and parents find uncomfortable. As AI tools become more integrated into classrooms, schools may need clearer policies and safeguards to navigate these competing concerns.

*— GIZMODO*<hr><h1>Cruz Demands Wikipedia Show No Ideological Bias</h1>Senator Ted Cruz (R‑TX) sent a formal letter to the Wikimedia Foundation on October 3, demanding evidence that the nonprofit operator of Wikipedia is free from ideological bias.  The letter accuses the encyclopedia of a left‑wing tilt, citing a conservative study by the Manhattan Institute that found liberal bias in many articles.  Cruz singled out the “Reliable Sources” list, noting that MSNBC and CNN are marked “generally reliable,” while Fox News is “generally unreliable.”  He also pointed to the Southern Poverty Law Center’s top rating versus the Heritage Foundation’s “blacklisted” status, arguing that such designations reflect a partisan agenda.

Cruz asked for documents showing how the Foundation and the Wikipedia community decide source ratings, how it counters “coordinated editing campaigns,” and how it addresses political or ideological bias.  He referenced the Foundation’s 2020 downgrade of Fox News, citing the outlet’s coverage of COVID‑19 and climate change.  He further alleged that the Foundation financially backs left‑leaning groups that influence Wikipedia content and that a “coordinated group of editors” promoted antisemitic narratives while white‑washing Hamas.  He acknowledged that the Foundation banned eight editors in January over Israeli‑Palestinian edit wars but questioned the motives behind its interventions.

In response, the Wikimedia Foundation confirmed receipt of Cruz’s letter and reiterated its commitment to free expression, editorial standards, and transparent processes.  It emphasized that nearly 260,000 volunteers have created over 65 million articles in 300 languages and that the platform is “always improving” and seeks to inform rather than persuade.

Cruz’s letter arrived two weeks after he criticized FCC Chairman Brendan Carr for threatening ABC with license revocations over political content on *Jimmy Kimmel Live!*.  He warned that using the government to dictate media speech would “end up bad for conservatives” and that future Democratic administrations would silence dissent.  As chair of the Senate Commerce, Science, and Transportation Committee, Cruz invoked the Standing Rules of the Senate to assert that the committee has jurisdiction over online information platforms and requested that the Foundation provide written responses and requested documents by October 17, 2025.

The letter also fits into Cruz’s broader investigation of the Biden administration’s alleged censorship.  He has released a report claiming that the Cybersecurity and Infrastructure Security Agency (CISA) has been turned into a “censorship agent” pressuring Big Tech to police speech and has scheduled a hearing titled “Shut Your App: How Uncle Sam Jawboned Big Tech Into Silencing Americans.”  His Wikimedia request includes a demand for all communications between the Foundation and any federal agency since January 1, 2020, which could feed into those investigations.

Ars Technica notes that it has long separated signal from noise, providing a trusted source of information.  This summary condenses the key points of Cruz’s letter, the Foundation’s response, and the broader political context into under 500 words.<hr>